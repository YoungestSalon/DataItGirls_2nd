{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 청원목록 크롤러"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "  Using cached https://files.pythonhosted.org/packages/5f/25/e52d3f31441505a5f3af41213346e5b6c221c9e086a166f3703d2ddaf940/pip-18.0-py2.py3-none-any.whl\n",
      "Installing collected packages: pip\n",
      "  Found existing installation: pip 10.0.1\n",
      "    Uninstalling pip-10.0.1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not install packages due to an EnvironmentError: [WinError 5] 액세스가 거부되었습니다: 'c:\\\\programdata\\\\anaconda3\\\\lib\\\\site-packages\\\\pip\\\\_internal\\\\basecommand.py'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "You are using pip version 10.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n",
      "Invalid requirement: '#'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\requirements.py\", line 93, in __init__\n",
      "    req = REQUIREMENT.parseString(requirement_string)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 1632, in parseString\n",
      "    raise exc\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 1622, in parseString\n",
      "    loc, tokens = self._parse( instring, 0 )\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 1379, in _parseNoCache\n",
      "    loc,tokens = self.parseImpl( instring, preloc, doActions )\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 3395, in parseImpl\n",
      "    loc, exprtokens = e._parse( instring, loc, doActions )\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 1379, in _parseNoCache\n",
      "    loc,tokens = self.parseImpl( instring, preloc, doActions )\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 3717, in parseImpl\n",
      "    return self.expr._parse( instring, loc, doActions, callPreParse=False )\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 1379, in _parseNoCache\n",
      "    loc,tokens = self.parseImpl( instring, preloc, doActions )\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 3378, in parseImpl\n",
      "    loc, resultlist = self.exprs[0]._parse( instring, loc, doActions, callPreParse=False )\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 1383, in _parseNoCache\n",
      "    loc,tokens = self.parseImpl( instring, preloc, doActions )\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pyparsing.py\", line 2689, in parseImpl\n",
      "    raise ParseException(instring, loc, self.errmsg, self)\n",
      "pip._vendor.pyparsing.ParseException: Expected W:(abcd...) (at char 0), (line:1, col:1)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_internal\\req\\req_install.py\", line 252, in from_line\n",
      "    req = Requirement(req)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\requirements.py\", line 97, in __init__\n",
      "    requirement_string[e.loc:e.loc + 8]))\n",
      "pip._vendor.packaging.requirements.InvalidRequirement: Invalid requirement, parse error at \"'#'\"\n",
      "\n",
      "You are using pip version 10.0.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --upgrade pip\n",
    "!pip install html5lib beautifulsoup4   # HTML을 받아오기 위한 설치 작업\n",
    "\n",
    "from urllib import request   # HTML을 받아오기 위한 import\n",
    "from bs4 import BeautifulSoup  # HTML 문자열을 분석하여 DOM을 구성하기 위한 import\n",
    "\n",
    "import pandas as pd   # 데이터프레임 처리/분석을 위한 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번호, 분류, 제목, 참여인원을 불러오면 앞뒤로 붙어있는 텍스트를 지우기 위한 함수.\n",
    "# 참여인원은 \"명\"이 추가로 붙어 있으니 참여인원할 때 추가 작업이 필요.\n",
    "\n",
    "# '>' 라는 문자를 기준으로 자르고(split), 자른 결과의 4번째('[3]') 요소를 선택해서,\n",
    "# 다시 '<' 라는 문자 기준으로 자른 다음 1번째('[0]') 요소를 선택하여 출력한다.\n",
    "\n",
    "def to_return(raw):\n",
    "  result = raw.split(\">\")[3].split(\"<\")[0]\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번호 : to_return 함수를 호출해서 bl_no의 앞뒤 텍스트를 지우고 no이라는 리스트에 넣는다.\n",
    "\n",
    "def return_no(bs):\n",
    "\n",
    "  bl_no = bs.select('.wrap > .board.text .bl_body ul li .bl_wrap .bl_no')\n",
    "\n",
    "  no = []\n",
    "  i_no = 0   # bl_no가 리스트 타입이기 때문에 1개씩 불러오려면 인덱스가 필요하다.\n",
    "\n",
    "  for num in bl_no:   # bl_no를 1개씩 순차적으로 불러오기 위한 반복문\n",
    "    num = str(bl_no[i_no])   # bl_no의 요소는 nontype → str으로 바꿔야 to_return 함수에서 split가 가능\n",
    "    no.append(int(to_return(num)))   # to_return의 결과값은 str이므로 int로 변경해서 저장\n",
    "    i_no = i_no + 1\n",
    "  \n",
    "  return no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류 : to_return 함수를 호출해서 bl_category의 앞뒤 텍스트를 지우고 category라는 리스트에 넣는다.\n",
    "\n",
    "def return_category(bs):\n",
    "  \n",
    "  bl_category = bs.select('.wrap > .board.text .bl_body ul li .bl_wrap .bl_category.cs')\n",
    "\n",
    "  category = []\n",
    "  i_cate = 0\n",
    "\n",
    "  for catego in bl_category:\n",
    "    catego = str(bl_category[i_cate])\n",
    "    category.append(to_return(catego))\n",
    "    i_cate = i_cate + 1\n",
    "  \n",
    "  return category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 참여인원 : to_return 함수를 호출해서 bl_agree의 앞뒤 텍스트를 지우고, \n",
    "# 추가 작업을 한 후 num_agree라는 리스트에 넣는다.\n",
    "\n",
    "def return_agree(bs):\n",
    "\n",
    "  # 'bl_agree_cb'가 대부분이지만 'bl_agree_cs'가 간혹 있음 : 'bl_agree'로 읽으면 모두 불려옴\n",
    "  bl_agree = bs.select('.wrap > .board.text .bl_body ul li .bl_wrap .bl_agree')\n",
    "  \n",
    "  num_agree = []\n",
    "  i_agree = 0\n",
    "\n",
    "  for agree in bl_agree:\n",
    "    agree = str(bl_agree[i_agree])\n",
    "  \n",
    "    # 참여인원은 글 번호와 다르게 숫자 뒤에 \"명\"과 빈 칸이 붙어 있어서 지워야 함.\n",
    "    no_agree = to_return(agree).split(\"명\")[0]\n",
    "  \n",
    "    num_agree.append(no_agree)\n",
    "    i_agree = i_agree + 1\n",
    "\n",
    "  return num_agree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제목 : to_return 함수를 호출해서 bl_subject의 앞뒤 텍스트를 지우고 subject라는 리스트에 넣는다.\n",
    "\n",
    "def return_sub(bs):\n",
    "\n",
    "  bl_subject = bs.select('.wrap > .board.text .bl_body ul li .bl_wrap .bl_subject a')\n",
    "\n",
    "  subject = []\n",
    "  i_subject = 0\n",
    "\n",
    "  for sub in bl_subject:\n",
    "    sub = str(bl_subject[i_subject])\n",
    "    subject.append(to_return(sub))\n",
    "    i_subject = i_subject + 1\n",
    "\n",
    "  return subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임에 데이터를 추가하는 함수\n",
    "\n",
    "def return_df(page):\n",
    "  \n",
    "  # HTML 받아오기\n",
    "  \n",
    "  with request.urlopen(page) as f:\n",
    "    charset = f.headers.get_content_charset()\n",
    "    html = f.read().decode(charset)\n",
    "   \n",
    "  # HTML 문자열을 분석하여 DOM 구성하기\n",
    "\n",
    "  bs = BeautifulSoup(html, 'html5lib')\n",
    "\n",
    "  # 각 페이지의 번호, 분류, 제목, 참여인원 데이터를 뽑아 데이터프레임에 추가한다.\n",
    "\n",
    "  no = return_no(bs)\n",
    "  category = return_category(bs)\n",
    "  subject = return_sub(bs)\n",
    "  num_agree = return_agree(bs)\n",
    "  \n",
    "  # 크롤링 시 array 문제가 생기면, 오류 발생 위치를 확인하기 위한 코드 \n",
    "  # print(len(no), len(category), len(subject), len(num_agree), int(i))\n",
    "  \n",
    "  option_list = {'No': no, 'Category': category, 'Subject': subject, 'Agree': num_agree}\n",
    "  df_pg = pd.DataFrame(option_list, columns = ['No', 'Category', 'Subject', 'Agree'])\n",
    "  \n",
    "  return df_pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 페이지 주소 자동 생성\n",
    "\n",
    "def page_url(pg_num):\n",
    "  page = \"https://www1.president.go.kr/petitions?page=\" + str(pg_num)\n",
    "  return page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16579"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 청원 목록 한 페이지의 게시물 수는?\n",
    "df_leng_of_page = return_df(page_url(0))\n",
    "leng_of_page = len(df_leng_of_page.index)\n",
    "\n",
    "# 현재 시점 기준 청원 목록의 마지막 번호는?\n",
    "last_page_url = page_url(1)\n",
    "last_page = return_df(last_page_url)\n",
    "\n",
    "# 청원 목록의 페이지 수는? (= 마지막 번호 / 한 페이지 게시물 수)\n",
    "pg_no = int(int(last_page.iloc[0,0]) / leng_of_page)\n",
    "\n",
    "# 청원 목록의 페이지 번호는 1번에서 시작하지만, 파이썬 인덱스는 0에서 시작한다.\n",
    "# 그래서, 실제 마지막 페이지 번호는 1만큼 더해줘야 한다.\n",
    "pg_num = pg_no + 1\n",
    "\n",
    "pg_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [WinError 10060] 연결된 구성원으로부터 응답이 없어 연결하지 못했거나, 호스트로부터 응답이 없어 연결이 끊어졌습니다>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1317\u001b[0m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[1;32m-> 1318\u001b[1;33m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0m\u001b[0;32m   1319\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# timeout error\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1238\u001b[0m         \u001b[1;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1284\u001b[0m             \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1285\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mendheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1233\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1234\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1025\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1026\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1027\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    963\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 964\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    965\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1392\u001b[1;33m             \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    935\u001b[0m         self.sock = self._create_connection(\n\u001b[1;32m--> 936\u001b[1;33m             (self.host,self.port), self.timeout, self.source_address)\n\u001b[0m\u001b[0;32m    937\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetsockopt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIPPROTO_TCP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTCP_NODELAY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address)\u001b[0m\n\u001b[0;32m    723\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 724\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    725\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address)\u001b[0m\n\u001b[0;32m    712\u001b[0m                 \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 713\u001b[1;33m             \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    714\u001b[0m             \u001b[1;31m# Break explicitly a reference cycle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTimeoutError\u001b[0m: [WinError 10060] 연결된 구성원으로부터 응답이 없어 연결하지 못했거나, 호스트로부터 응답이 없어 연결이 끊어졌습니다",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-88a086a91656>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# for i in range (15):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m   \u001b[0mdata_pg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturn_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-87b83589d6e9>\u001b[0m in \u001b[0;36mreturn_df\u001b[1;34m(page)\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[1;31m# HTML 받아오기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m   \u001b[1;32mwith\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mcharset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_content_charset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mhtml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcharset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    524\u001b[0m             \u001b[0mreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[1;31m# post-process response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    542\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[1;32m--> 544\u001b[1;33m                                   '_open', req)\n\u001b[0m\u001b[0;32m    545\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    502\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    505\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1359\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[1;32m-> 1361\u001b[1;33m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0m\u001b[0;32m   1362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m         \u001b[0mhttps_request\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1318\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0;32m   1319\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# timeout error\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1320\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1321\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mURLError\u001b[0m: <urlopen error [WinError 10060] 연결된 구성원으로부터 응답이 없어 연결하지 못했거나, 호스트로부터 응답이 없어 연결이 끊어졌습니다>"
     ]
    }
   ],
   "source": [
    "data_petitions = pd.DataFrame()   # 데이터를 추가할 빈 그릇을 하나 만든다.\n",
    "i = 1   # for문으로 반복시키기 위한 index 번호도 한 개 만든다.\n",
    "\n",
    "\n",
    "# 청원목록 전체 크롤링. (주의 : 오래 걸림 / 기준 시점 : 20180728 PM 11:37)\n",
    "for i in range (pg_num):\n",
    "\n",
    "# for i in range (15):  \n",
    "\n",
    "  data_pg = return_df(page_url(i))\n",
    "  \n",
    "  if i == 0:\n",
    "    data_list = data_petitions.append(data_pg, ignore_index = True)\n",
    "\n",
    "  else:\n",
    "    data_list = data_list.append(data_pg, ignore_index = True)\n",
    "\n",
    "  i = i + 1\n",
    "    \n",
    "data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류와 제목을 기준으로 중복된 행을 제거한다. \n",
    "# 도배 게시물을 제거하여 분석의 정확성을 높이는 목적\n",
    "\n",
    "list_result = data_list.drop_duplicates([\"Category\", \"Subject\"], keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 청원목록 전체 크롤링 자료에 대한 작업용 복사본 생성\n",
    "    \n",
    "petitions_all_list = list_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링 완료된 자료를 Excel에 저장\n",
    "\n",
    "list_result.to_excel('petitions_data.xlsx', sheet_name='list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excel에 저장한 자료를 읽어올 수 있음\n",
    "\n",
    "pd.read_excel('petitions_data.xlsx', 'list', index_col=None, na_values=['NA'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 청원 본문 크롤러"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install --upgrade pip\n",
    "!pip install html5lib beautifulsoup4   # HTML을 받아오기 위한 설치 작업\n",
    "!pip install -q 'soynlp[all]'   # 자연어 처리/분석을 위한 soynlp 설치 작업\n",
    "!pip show soynlp   # 자연어 처리/분석을 위한 soynlp 설치 작업 2\n",
    "\n",
    "from urllib import request   # HTML을 받아오기 위한 import\n",
    "from bs4 import BeautifulSoup   # HTML 문자열을 분석하여 DOM을 구성하기 위한 import\n",
    "\n",
    "import pandas as pd   # 데이터프레임 처리/분석을 위한 import\n",
    "import numpy as np   # 데이터프레임 처리/분석을 위한 import 2\n",
    "import re   # 정규표현식 사용을 위한 import\n",
    "import random   # Random 선택 사용을 위한 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제목을 불러오면 앞뒤로 붙어있는 텍스트를 지우기 위한 함수.\n",
    "\n",
    "# '>' 라는 문자를 기준으로 자르고(split), 자른 결과의 4번째('[1]') 요소를 선택해서,\n",
    "# 다시 '<' 라는 문자 기준으로 자른 다음 1번째('[0]') 요소를 선택하여 출력한다.\n",
    "\n",
    "def to_cleaning(raw):\n",
    "  result = raw.split(\">\")[1].split(\"<\")[0]\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제목을 불러오는 함수\n",
    "\n",
    "def return_title(bs_contents):\n",
    "\n",
    "  ti = bs_contents.select('.petitionsView_left_pg .petitionsView_title')\n",
    "  #title = ti[0]\n",
    "\n",
    "  title = []   # \"ValueError: If using all scalar values, you must pass an index site\" 방지 : 리스트로 변환\n",
    "\n",
    "  title_text = str(ti)   # ti를 str으로 바꿔서 to_cleaning 함수에서 split가 가능하도록 만듦\n",
    "  title.append(to_cleaning(title_text))\n",
    "  \n",
    "  return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 본문 : 개행문자 / HTML 코드 제거를 위한 함수\n",
    "\n",
    "def preprocessing_con(con_clear):\n",
    "  con_clear = re.sub('\\t', '', con_clear)\n",
    "  con_clear = re.sub('\\n', '', con_clear)\n",
    "  con_clear = re.sub('<br>', '', con_clear)\n",
    "  con_clear = re.sub('<br/>', '', con_clear)\n",
    "  con_clear = re.sub('<div class=\"View_write\" style=\"word-break:break-all\">', '', con_clear)\n",
    "  con_clear = re.sub('&lt;', '', con_clear)\n",
    "  con_clear = re.sub('&gt;', '', con_clear)\n",
    "  con_clear = re.sub('</div>', '', con_clear) \n",
    "  con_clear = re.sub('\\[', '', con_clear)\n",
    "  con_clear = re.sub('\\]', '', con_clear)  \n",
    "  return con_clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 본문을 불러오는 함수 : 개행문자 제거를 위해 preprocessing_con 함수를 호출함\n",
    "\n",
    "def return_contents(bs_contents):\n",
    "\n",
    "  con = bs_contents.select('.petitionsView_left_pg .petitionsView_write .View_write')\n",
    "  \n",
    "  contents = []   # \"ValueError: If using all scalar values, you must pass an index site\" 방지 : 리스트로 변환\n",
    "\n",
    "  contents_text = str(con)   # con을 str으로 바꿔서 to_cleaning 함수에서 split가 가능하도록 만듦\n",
    "  contents.append(preprocessing_con(contents_text))\n",
    "   \n",
    "  return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 페이지 주소 자동 생성\n",
    "\n",
    "def page_url_con(pg_con):\n",
    "  page_contents = \"https://www1.president.go.kr/petitions/\" + str(pg_con)\n",
    "  return page_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임에 데이터를 추가하는 함수\n",
    "\n",
    "def return_df_contents(page_contents):\n",
    "  \n",
    "  # HTML 받아오기\n",
    "  \n",
    "  with request.urlopen(page_contents) as f:\n",
    "    charset = f.headers.get_content_charset()\n",
    "    html = f.read().decode(charset)\n",
    "   \n",
    "  # HTML 문자열을 분석하여 DOM 구성하기\n",
    "\n",
    "  bs_contents = BeautifulSoup(html, 'html5lib')\n",
    "\n",
    "  # 각 페이지의 제목, 본문 데이터를 뽑아 데이터프레임에 추가한다.\n",
    "\n",
    "  title = return_title(bs_contents)\n",
    "  contents = return_contents(bs_contents)\n",
    "  \n",
    "  # 크롤링 시 array 문제가 생기면, 오류 발생 위치를 확인하기 위한 코드 \n",
    "  # a = print(len(title), len(contents), int(i))\n",
    "  \n",
    "  option_list_con = {'Title': title, 'Contents': contents}\n",
    "  df_contents = pd.DataFrame(option_list_con, columns = ['Title', 'Contents'])\n",
    "  \n",
    "  return df_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q. 현재 시점 기준 청원 목록의 마지막 번호에 해당하는 본문 페이지의 번호는?\n",
    "# A. 청원목록 1페이지의 가장 최신글 제목에 설정되어 있는 링크를 가져오면 된다.\n",
    "\n",
    "# 우선 청원목록 1페이지를 가져온다.\n",
    "page_last = \"https://www1.president.go.kr/petitions?page=1\"\n",
    "\n",
    "# 청원목록 1페이지의 HTML을 받아온 후,\n",
    "with request.urlopen(page_last) as f:\n",
    "    charset = f.headers.get_content_charset()\n",
    "    html = f.read().decode(charset)\n",
    "\n",
    "# 청원목록 1페이지의 HTML DOM을 구성한다.\n",
    "last_pg = BeautifulSoup(html, 'html5lib')\n",
    "\n",
    "# 제목 부분만 뽑아온 후,\n",
    "bl_last = last_pg.select('.wrap > .board.text .bl_body ul li .bl_wrap .bl_subject a')\n",
    "\n",
    "# 제목 중에서도 가장 최신글만 선택해서,\n",
    "last = str(bl_last[0])\n",
    "\n",
    "# 숫자 부분만 split로 뽑아낸 다음, \n",
    "last_num = last.split(\"\\\"\")[3].split(\"/\")[4].split(\"?\")[0]\n",
    "\n",
    "# str으로 split 작업한 결과물을 int로 변경한다.\n",
    "last_num_int = int(last_num)\n",
    "\n",
    "last_num_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_petitions_contents = pd.DataFrame()   # 데이터를 추가할 빈 그릇을 하나 만든다.\n",
    "\n",
    "# for문으로 반복시키기 위한 index 번호도 한 개 만든다.\n",
    "# 청와대 국민청원 본문 페이지는 21번부터 시작하므로 index도 21번부터 시작해야 한다.\n",
    "i = 21\n",
    "\n",
    "# for문으로 반복시킬 때, exception 처리 되지 않은 첫 번째 결과값에 대해 빈 그릇을 적용해야 한다.\n",
    "# exception 처리 되지 않은 첫 번째 결과값 여부를 판단하기 위한 index를 한 개 만든다.\n",
    "try_num = 0\n",
    "\n",
    "# 청원 본문 전체 크롤링. (주의 : 오래 걸림 / 기준 시점 : 20180728 PM 3:00)\n",
    "# for i in range (21, last_num_int): (전체 크롤링은 너무 오래 걸려서 잠깐 봉인...)\n",
    "\n",
    "for i in range (313457, 313459):\n",
    "\n",
    "  while True:\n",
    "    try:\n",
    "      data_content = return_df_contents(page_url_con(i))\n",
    "     \n",
    "    except Exception:\n",
    "      continue\n",
    "\n",
    "  try_num = try_num + 1\n",
    "  \n",
    "  if try_num == 1:\n",
    "    data_list_contents = data_petitions_contents.append(data_content, ignore_index = True)\n",
    "    \n",
    "  else:\n",
    "    data_list_contents = data_list_contents.append(data_content, ignore_index = True)\n",
    "    \n",
    "  i = i + 1\n",
    "  \n",
    "  a = data_list_contents\n",
    "    \n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제목을 기준으로 중복된 행을 제거한다. \n",
    "# 도배 게시물을 제거하여 분석의 정확성을 높이는 목적\n",
    "\n",
    "contents_result = data_list_contents.drop_duplicates([\"Title\"], keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 청원목록 전체 크롤링 자료에 대한 작업용 복사본 생성\n",
    "    \n",
    "petitions_all_contents = contents_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링 완료된 자료를 Excel에 저장\n",
    "\n",
    "contents_result.to_excel('petitions_data.xlsx', sheet_name='contents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excel에 저장한 자료를 읽어올 수 있음\n",
    "\n",
    "pd.read_excel('petitions_data.xlsx', 'contents', index_col=None, na_values=['NA'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
